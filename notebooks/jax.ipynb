{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax\n",
    "import torch\n",
    "from functools import partial\n",
    "import abc\n",
    "import jumanji\n",
    "from flax import struct\n",
    "from jumanji.env import State\n",
    "import jax.random as random\n",
    "import orbax.checkpoint\n",
    "\n",
    "import optax\n",
    "\n",
    "from typing import Optional, Any\n",
    "import shutil\n",
    "\n",
    "from flax.training import checkpoints, train_state\n",
    "from flax import struct, serialization\n",
    "import orbax.checkpoint\n",
    "\n",
    "import optax as opx\n",
    "import flashbax as fbx\n",
    "import chex\n",
    "from typing import TypeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = TypeVar(\"Experience\", bound=chex.ArrayTree)\n",
    "\n",
    "@struct.dataclass\n",
    "class BufferState:\n",
    "    needs_reward: jnp.ndarray\n",
    "    buffer: Experience\n",
    "    next_index: int\n",
    "    batch_size: int\n",
    "    max_len_per_batch: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from flashbax\n",
    "def init_buffer_state(\n",
    "    experience: Experience,\n",
    "    batch_size: int,\n",
    "    max_len_per_batch: int\n",
    ") -> BufferState:\n",
    "    \n",
    "    experience = jax.tree_map(jnp.empty_like, experience)\n",
    "\n",
    "    experience = jax.tree_map(\n",
    "        lambda x: jnp.broadcast_to(\n",
    "            x[None, None,...], (batch_size, max_len_per_batch, *x.shape)\n",
    "        ),\n",
    "        experience,\n",
    "    )\n",
    "\n",
    "    return BufferState(\n",
    "        buffer=experience,\n",
    "        next_index=0,\n",
    "        needs_reward=jnp.zeros((batch_size, max_len_per_batch, 1), dtype=jnp.bool_),\n",
    "        max_len_per_batch=max_len_per_batch,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "def add_experience(\n",
    "    buffer_state: BufferState,\n",
    "    experience: Experience\n",
    ") -> BufferState:\n",
    "\n",
    "    def add_item(items, new_item):\n",
    "        return items.at[:, buffer_state.next_index].set(new_item)\n",
    "\n",
    "    updated_pytree = jax.tree_map(add_item, buffer_state.buffer, experience)\n",
    "\n",
    "    # Update the next index\n",
    "    needs_reward = buffer_state.needs_reward.at[:, buffer_state.next_index, 0].set(True)\n",
    "    updated_next_index = (buffer_state.next_index + 1) % buffer_state.max_len_per_batch\n",
    "    \n",
    "    return buffer_state.replace(\n",
    "        buffer=updated_pytree,\n",
    "        next_index=updated_next_index,\n",
    "        needs_reward=needs_reward\n",
    "    )\n",
    "\n",
    "def assign_rewards(\n",
    "    buffer_state: BufferState,\n",
    "    rewards: jnp.ndarray,\n",
    "    select_batch: jnp.ndarray,\n",
    "    reward_field: str = \"reward\"\n",
    ") -> BufferState:\n",
    "    buffer_state.buffer[reward_field] += rewards * buffer_state.needs_reward * select_batch\n",
    "\n",
    "    return buffer_state.replace(\n",
    "        needs_reward = buffer_state.needs_reward * (1 - select_batch)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "buff_state = init_buffer_state(\n",
    "    {\"obs\": jnp.array([0, 0]), \"reward\": jnp.array([0])},\n",
    "    batch_size=4,\n",
    "    max_len_per_batch=100\n",
    ")\n",
    "\n",
    "for j in range(10):\n",
    "    buff_state = add_experience(\n",
    "        buff_state,\n",
    "        {\"obs\": jnp.stack([jnp.array([j, i]) for i in range(4)]), \"reward\": jnp.stack([jnp.array([0]) for i in range(4)])}\n",
    "    )\n",
    "\n",
    "buff_state = assign_rewards(\n",
    "    buff_state,\n",
    "    jnp.array([1, 2, 3, 4]).reshape(-1, 1, 1),\n",
    "    jnp.array([1, 1, 0, 1]).reshape(-1, 1, 1)\n",
    ")\n",
    "\n",
    "for j in range(10):\n",
    "    buff_state = add_experience(\n",
    "        buff_state,\n",
    "        {\"obs\": jnp.stack([jnp.array([j, i]) for i in range(4)]), \"reward\": jnp.stack([jnp.array([0]) for i in range(4)])}\n",
    "    )\n",
    "\n",
    "buff_state = assign_rewards(\n",
    "    buff_state,\n",
    "    jnp.array([5, 6, 7, 8]).reshape(-1, 1, 1),\n",
    "    jnp.array([1, 0, 1, 1]).reshape(-1, 1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class MCTS_State(abc.ABC):\n",
    "    env_state: State\n",
    "    action_map: jnp.ndarray\n",
    "    p_vals: jnp.ndarray\n",
    "    n_vals: jnp.ndarray\n",
    "    w_vals: jnp.ndarray\n",
    "    actions_taken: jnp.ndarray\n",
    "    visits: jnp.ndarray\n",
    "    next_empty: jnp.ndarray\n",
    "    cur_node: jnp.ndarray\n",
    "    depth: jnp.ndarray\n",
    "    subtrees: jnp.ndarray\n",
    "    parents: jnp.ndarray\n",
    "    rng: PRNGKeyArray\n",
    "\n",
    "def init_state(\n",
    "    keys: PRNGKeyArray\n",
    "):\n",
    "    max_nodes = 100\n",
    "    policy_size = 10\n",
    "    total_slots = 2 + max_nodes\n",
    "    std_shape = (total_slots, policy_size)\n",
    "\n",
    "    visits = jnp.zeros(max_nodes + 1, dtype=jnp.int32)\n",
    "    visits.at[0].set(1)\n",
    "\n",
    "    state = MCTS_State(\n",
    "        action_map=jnp.zeros(std_shape, dtype=jnp.int32),\n",
    "        p_vals=jnp.zeros(std_shape, dtype=jnp.float32),\n",
    "        n_vals=jnp.zeros(std_shape, dtype=jnp.float32),\n",
    "        w_vals=jnp.zeros(std_shape, dtype=jnp.float32),\n",
    "        actions_taken=jnp.zeros(max_nodes + 1, dtype=jnp.int32),\n",
    "        visits=visits,\n",
    "        next_empty=jnp.full(1, 2, dtype=jnp.int32),\n",
    "        cur_node=jnp.ones(1, dtype=jnp.int32),\n",
    "        depth=jnp.zeros(1, dtype=jnp.int32),\n",
    "        subtrees=jnp.zeros(1, dtype=jnp.int32),\n",
    "        parents=jnp.zeros(1, dtype=jnp.int32),\n",
    "        rng=keys\n",
    "    )\n",
    "\n",
    "    return state\n",
    "\n",
    "class MCTS_Evaluator:\n",
    "    def __init__(self, env):\n",
    "        self.state = None\n",
    "        self.env = env\n",
    "\n",
    "    def reset(self, keys):\n",
    "        return init_state(keys), self.env.reset(keys)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = jax.random.split(jax.random.PRNGKey(0), 5)\n",
    "evaluator = MCTS_Evaluator(env)\n",
    "\n",
    "mcts, (state, timestep) = jax.vmap(evaluator.reset)(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turbozero-mMa0U6zx-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
