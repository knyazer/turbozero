{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSUEDOCODE\n",
    "* one iteration of selfplay collection takes N steps\n",
    "* environments are reset when they terminate (or are truncated)\n",
    "* trajectories are placed in batched replay memory buffer\n",
    "* rewards are assigned to trajectories after episode is completed\n",
    "\n",
    "* once a selfplay collection iteration is completed, T training steps are taken\n",
    "* a training step involves gathering a mini-batch of size M trajectories from non-truncated, terminated episodes in the replay memory buffer\n",
    "* a trajectory includes metadata necessary to train a model\n",
    "    * in the case of AZ, this include action visit counts, and final episode reward\n",
    "* compare model output to metadata, compute loss, SGD, etc\n",
    "\n",
    "* C collection steps makes up one training epoch\n",
    "* do whatever to evaluate\n",
    "\n",
    "\n",
    "def train():\n",
    "    for _ in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import struct\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience(struct.PyTreeNode):\n",
    "    obs: jnp.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core_jax.utils.replay_memory import EndRewardReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(rng, batch_size, max_len_per_batch, sample_batch_size):\n",
    "\n",
    "    buff = EndRewardReplayBuffer(\n",
    "        template_experience=Experience(obs=jnp.array([0, 0])),\n",
    "        batch_size=batch_size,\n",
    "        max_len_per_batch=max_len_per_batch,\n",
    "        sample_batch_size=sample_batch_size\n",
    "    )\n",
    "    \n",
    "    for j in range(11):\n",
    "        buff.add_experience(\n",
    "            Experience(obs=jnp.stack([jnp.array([j, i]) for i in range(4)]))\n",
    "        )\n",
    "\n",
    "\n",
    "    buff.assign_rewards(\n",
    "        jnp.array([[1,0], [0.5,0.5], [0,1], [0.5, 0.5]]).reshape(-1, 2),\n",
    "        jnp.array([True, True, False, True])\n",
    "    )\n",
    "\n",
    "    for j in range(11):\n",
    "        buff.add_experience(\n",
    "            Experience(obs=jnp.stack([jnp.array([j+11, i]) for i in range(4)]))\n",
    "        )\n",
    "\n",
    "    buff.assign_rewards(\n",
    "        jnp.array([[1,0], [1,0], [1,0], [1, 0]]).reshape(-1, 2),\n",
    "        jnp.array([True, False, True, True])\n",
    "    )\n",
    "    \n",
    "    buff.truncate(\n",
    "        jnp.array([False, True, True, False])\n",
    "    )\n",
    "\n",
    "    return buff.sample(rng), buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Experience(obs=Array([[ 3,  1],\n",
       "        [ 3,  2],\n",
       "        [ 8,  1],\n",
       "        [ 7,  0],\n",
       "        [20,  3],\n",
       "        [21,  2],\n",
       "        [ 2,  2],\n",
       "        [ 3,  0],\n",
       "        [11,  3],\n",
       "        [12,  0]], dtype=int32)),\n",
       " Array([[0.5],\n",
       "        [0. ],\n",
       "        [0.5],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [0. ],\n",
       "        [1. ],\n",
       "        [0. ]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, buff = test(jax.random.PRNGKey(6), 4, 30, 10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]], dtype=bool)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buff.state.needs_reward[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class MCTS_State(abc.ABC):\n",
    "    env_state: State\n",
    "    action_map: jnp.ndarray\n",
    "    p_vals: jnp.ndarray\n",
    "    n_vals: jnp.ndarray\n",
    "    w_vals: jnp.ndarray\n",
    "    actions_taken: jnp.ndarray\n",
    "    visits: jnp.ndarray\n",
    "    next_empty: jnp.ndarray\n",
    "    cur_node: jnp.ndarray\n",
    "    depth: jnp.ndarray\n",
    "    subtrees: jnp.ndarray\n",
    "    parents: jnp.ndarray\n",
    "    rng: PRNGKeyArray\n",
    "\n",
    "def init_state(\n",
    "    keys: PRNGKeyArray\n",
    "):\n",
    "    max_nodes = 100\n",
    "    policy_size = 10\n",
    "    total_slots = 2 + max_nodes\n",
    "    std_shape = (total_slots, policy_size)\n",
    "\n",
    "    visits = jnp.zeros(max_nodes + 1, dtype=jnp.int32)\n",
    "    visits.at[0].set(1)\n",
    "\n",
    "    state = MCTS_State(\n",
    "        action_map=jnp.zeros(std_shape, dtype=jnp.int32),\n",
    "        p_vals=jnp.zeros(std_shape, dtype=jnp.float32),\n",
    "        n_vals=jnp.zeros(std_shape, dtype=jnp.float32),\n",
    "        w_vals=jnp.zeros(std_shape, dtype=jnp.float32),\n",
    "        actions_taken=jnp.zeros(max_nodes + 1, dtype=jnp.int32),\n",
    "        visits=visits,\n",
    "        next_empty=jnp.full(1, 2, dtype=jnp.int32),\n",
    "        cur_node=jnp.ones(1, dtype=jnp.int32),\n",
    "        depth=jnp.zeros(1, dtype=jnp.int32),\n",
    "        subtrees=jnp.zeros(1, dtype=jnp.int32),\n",
    "        parents=jnp.zeros(1, dtype=jnp.int32),\n",
    "        rng=keys\n",
    "    )\n",
    "\n",
    "    return state\n",
    "\n",
    "class MCTS_Evaluator:\n",
    "    def __init__(self, env):\n",
    "        self.state = None\n",
    "        self.env = env\n",
    "\n",
    "    def reset(self, keys):\n",
    "        return init_state(keys), self.env.reset(keys)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turbozero-mMa0U6zx-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
