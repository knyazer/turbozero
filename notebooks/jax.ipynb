{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from core.collector import Collector\n",
    "from core.envs.make import make_env\n",
    "from core.envs.pgx import make_pgx_env\n",
    "from core.evaluators.alphazero import AlphaZero, AlphaZeroConfig\n",
    "from core.evaluators.make import make_evaluator\n",
    "from core.memory.make import make_replay_buffer\n",
    "from core.networks.make import make_model\n",
    "from core.training.train import Trainer, TrainerConfig\n",
    "from core.memory.replay_memory import EndRewardReplayBuffer\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "max_len_per_batch = 1000\n",
    "sample_batch_size = 10\n",
    "\n",
    "env = make_env(\n",
    "    {\n",
    "        \"env_name\": \"othello\",\n",
    "        \"env_type\": \"pgx\",\n",
    "        \"base_config\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "model = make_model(\n",
    "    {\n",
    "        \"model_type\": \"az_resnet\",\n",
    "        \"policy_head_out_size\": jnp.prod(jnp.array(env.get_action_shape())).item(),\n",
    "        \"value_head_out_size\": 1,\n",
    "        \"num_blocks\": 2,\n",
    "        \"channels\": 4\n",
    "    }\n",
    ")\n",
    "\n",
    "evaluator = make_evaluator(\n",
    "    {\n",
    "        \"evaluator_type\": \"alphazero\",\n",
    "        \"mcts_iters\": 100,\n",
    "        \"temperature\": 1.0,\n",
    "        \"epsilon\": 1e-8,\n",
    "        \"max_nodes\": 100,\n",
    "        \"puct_coeff\": 1.0,\n",
    "        \"dirichlet_alpha\": 0.3,\n",
    "        \"dirichlet_epsilon\": 0.25,\n",
    "    },\n",
    "    env,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "buff = make_replay_buffer(\n",
    "    {\n",
    "        \"buff_type\": \"end_reward\",\n",
    "        \"max_len_per_batch\": max_len_per_batch,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"sample_batch_size\": sample_batch_size\n",
    "    }\n",
    ")\n",
    "\n",
    "   \n",
    "trainer = Trainer(\n",
    "    config=TrainerConfig(\n",
    "        warmup_steps=100,\n",
    "        collection_steps_per_epoch=100,\n",
    "        train_steps_per_epoch=4,\n",
    "        epochs_per_checkpoint=1,\n",
    "        learning_rate=1e-3,\n",
    "        momentum=0.9,\n",
    "        policy_factor=1.0,\n",
    "        checkpoint_dir=\"../checkpoints/\",\n",
    "        max_checkpoints_to_keep=3\n",
    "    ),\n",
    "    env=env,\n",
    "    evaluator=evaluator,\n",
    "    buff=buff,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"test_az_0\",\n",
    "    config={\n",
    "        'train_config': trainer.config,\n",
    "        'model_config': model.config,\n",
    "        'env_config': env.config,\n",
    "        'evaluator_config': evaluator.config,\n",
    "        'buff_config': buff.config\n",
    "    }\n",
    ")\n",
    "\n",
    "state = trainer.init(jax.random.PRNGKey(0))\n",
    "\n",
    "trainer.train_loop(\n",
    "    state,\n",
    "    num_epochs = 10,\n",
    "    warmup=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turbozero-mMa0U6zx-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
