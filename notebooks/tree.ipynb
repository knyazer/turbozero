{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from core.memory.replay_memory import BaseExperience, EpisodeReplayBuffer\n",
    "from core.trees.tree import init_batched_tree\n",
    "from core.evaluators.mcts.mcts import MCTSTree, MCTSNode, MCTS\n",
    "\n",
    "env = pgx.make(\"othello\")\n",
    "BATCH_SIZE = 16\n",
    "MAX_NODES = 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "replay_memory = EpisodeReplayBuffer(capacity=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlowrollr\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/marshingjay/Repos/turbozero/notebooks/wandb/run-20240120_141737-5nopo23s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lowrollr/aztest/runs/5nopo23s' target=\"_blank\">drawn-gorge-7</a></strong> to <a href='https://wandb.ai/lowrollr/aztest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lowrollr/aztest' target=\"_blank\">https://wandb.ai/lowrollr/aztest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lowrollr/aztest/runs/5nopo23s' target=\"_blank\">https://wandb.ai/lowrollr/aztest/runs/5nopo23s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import functools\n",
    "import chex\n",
    "import optax\n",
    "from core.evaluators.alphazero import AlphaZero\n",
    "from core.evaluators.mcts.action_selection import MuZeroPUCTSelector\n",
    "from core.memory.replay_memory import BaseExperience, EpisodeReplayBuffer\n",
    "from core.networks.azresnet import AZResnet, AZResnetConfig\n",
    "from core.training.train import extract_params\n",
    "from core.training.train_2p import TwoPlayerTrainer\n",
    "from flax.training.train_state import TrainState\n",
    "\n",
    "from core.types import StepMetadata\n",
    "\n",
    "resnet = AZResnet(AZResnetConfig(\n",
    "    model_type=\"resnet\",\n",
    "    policy_head_out_size=65,\n",
    "    num_blocks=2,\n",
    "    num_channels=4,\n",
    "))\n",
    "\n",
    "def train_step(experience: BaseExperience, train_state: TrainState):\n",
    "    def loss_fn(params: chex.ArrayTree):\n",
    "        (pred_policy, pred_value), updates = train_state.apply_fn(\n",
    "            {'params': params, 'batch_stats': train_state.batch_stats}, \n",
    "            x=experience.env_state.observation,\n",
    "            train=True,\n",
    "            mutable=['batch_stats']\n",
    "        )\n",
    "        pred_policy = jnp.where(\n",
    "            experience.policy_mask,\n",
    "            pred_policy,\n",
    "            jnp.finfo(jnp.float32).min\n",
    "        )\n",
    "        policy_loss = optax.softmax_cross_entropy(pred_policy, experience.policy_weights).mean()\n",
    "        # select appropriate value from experience.reward\n",
    "        current_player = experience.env_state.current_player\n",
    "        target_value = experience.reward[jnp.arange(experience.reward.shape[0]), current_player]\n",
    "        value_loss = optax.l2_loss(pred_value.squeeze(), target_value).mean()\n",
    "\n",
    "        l2_reg = 0.0001 * jax.tree_util.tree_reduce(\n",
    "            lambda x, y: x + y,\n",
    "            jax.tree_map(\n",
    "                lambda x: (x ** 2).sum(),\n",
    "                params\n",
    "            )\n",
    "        )\n",
    "\n",
    "        loss = policy_loss + value_loss + l2_reg\n",
    "        return loss, ((policy_loss, value_loss, pred_policy, pred_value), updates)\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, ((policy_loss, value_loss, pred_policy, pred_value), updates)), grads = grad_fn(train_state.params)\n",
    "    train_state = train_state.apply_gradients(grads=grads)\n",
    "    train_state = train_state.replace(batch_stats=updates['batch_stats'])\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'policy_loss': policy_loss,\n",
    "        'value_loss': value_loss,\n",
    "        'policy_accuracy': jnp.mean(jnp.argmax(pred_policy, axis=-1) == jnp.argmax(experience.policy_weights, axis=-1)),\n",
    "        'value_accuracy': jnp.mean(jnp.round(pred_value) == jnp.round(experience.reward))\n",
    "    }\n",
    "    return train_state, metrics\n",
    "\n",
    "def step_fn(state, action):\n",
    "    state = env.step(state, action)\n",
    "    metadata = StepMetadata(\n",
    "        rewards = state.rewards,\n",
    "        terminated = state.terminated,\n",
    "        action_mask = state.legal_action_mask,\n",
    "        cur_player_id = state.current_player\n",
    "    )\n",
    "    return state, metadata\n",
    "\n",
    "def init_fn(key):\n",
    "    state = env.init(key)\n",
    "    metadata = StepMetadata(\n",
    "        rewards = state.rewards,\n",
    "        terminated = state.terminated,\n",
    "        action_mask = state.legal_action_mask,\n",
    "        cur_player_id = state.current_player\n",
    "    )\n",
    "    return state, metadata\n",
    "\n",
    "def eval_fn(state, params):\n",
    "    policy_logits, value = resnet.apply(params, state.observation[None,...], train=False)\n",
    "    return jax.nn.softmax(policy_logits, axis=-1).squeeze(0), \\\n",
    "            value.squeeze()\n",
    "\n",
    "trainer = TwoPlayerTrainer(\n",
    "    train_batch_size = 32,\n",
    "    env_step_fn = step_fn,\n",
    "    env_init_fn = init_fn,\n",
    "    eval_fn = eval_fn,\n",
    "    train_step_fn =  train_step,\n",
    "    evaluator = AlphaZero(\n",
    "        max_nodes = MAX_NODES,\n",
    "        branching_factor=65,\n",
    "        action_selection_fn = MuZeroPUCTSelector()\n",
    "    ),\n",
    "    memory_buffer = EpisodeReplayBuffer(capacity=1000),\n",
    "    evaluator_kwargs_train = dict(num_iterations=100),\n",
    "    evaluator_kwargs_test = dict(num_iterations=100),\n",
    "    wandb_project_name='aztest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainStateWithBS(TrainState):\n",
    "    batch_stats: chex.ArrayTree\n",
    "\n",
    "sample_env_state = trainer.make_template_env_state()\n",
    "\n",
    "variables = resnet.init(jax.random.PRNGKey(0), sample_env_state.observation[None,...], train=False)\n",
    "params = variables['params']\n",
    "batch_stats = variables['batch_stats']\n",
    "\n",
    "train_state = TrainStateWithBS.create(\n",
    "    apply_fn = resnet.apply,\n",
    "    params = params,\n",
    "    tx = optax.adam(1e-4),\n",
    "    batch_stats = batch_stats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: {'loss': Array(2.8069592, dtype=float32), 'policy_accuracy': Array(0.17578125, dtype=float32), 'policy_loss': Array(2.1975522, dtype=float32), 'value_accuracy': Array(0.17285156, dtype=float32), 'value_loss': Array(0.597967, dtype=float32)}\n",
      "Epoch 1: {'batch_stats': {'BatchNorm_0': {'mean': Array([0., 0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1., 1.], dtype=float32)}, 'BatchNorm_1': {'mean': Array([0., 0.], dtype=float32), 'var': Array([1., 1.], dtype=float32)}, 'BatchNorm_2': {'mean': Array([0.], dtype=float32), 'var': Array([1.], dtype=float32)}, 'ResidualBlock_0': {'BatchNorm_0': {'mean': Array([0., 0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1., 1.], dtype=float32)}, 'BatchNorm_1': {'mean': Array([0., 0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1., 1.], dtype=float32)}}, 'ResidualBlock_1': {'BatchNorm_0': {'mean': Array([0., 0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1., 1.], dtype=float32)}, 'BatchNorm_1': {'mean': Array([0., 0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1., 1.], dtype=float32)}}}, 'params': {'BatchNorm_0': {'bias': Array([0., 0., 0., 0.], dtype=float32), 'scale': Array([1., 1., 1., 1.], dtype=float32)}, 'BatchNorm_1': {'bias': Array([0., 0.], dtype=float32), 'scale': Array([1., 1.], dtype=float32)}, 'BatchNorm_2': {'bias': Array([0.], dtype=float32), 'scale': Array([1.], dtype=float32)}, 'Conv_0': {'kernel': Array([[[[-0.42570192,  0.3228539 , -0.8729657 , -0.5388431 ],\n",
      "         [ 1.0411347 , -1.154814  , -0.33643174, -0.36595514]]]],      dtype=float32)}, 'Conv_1': {'kernel': Array([[[[ 0.8292069 , -0.42264014],\n",
      "         [ 0.44380084,  0.77679753],\n",
      "         [-0.74258596, -0.14605407],\n",
      "         [-0.7981471 , -0.30228698]]]], dtype=float32)}, 'Conv_2': {'kernel': Array([[[[-0.59903777],\n",
      "         [-0.9720155 ],\n",
      "         [-0.05978734],\n",
      "         [ 0.39322317]]]], dtype=float32)}, 'Dense_0': {'bias': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float32), 'kernel': Array([[-0.03902329, -0.05097247,  0.09989672, ..., -0.0926476 ,\n",
      "         0.13560821, -0.02722711],\n",
      "       [ 0.14758052, -0.08842497,  0.01819097, ..., -0.00611533,\n",
      "         0.14484653,  0.12210113],\n",
      "       [ 0.08703937, -0.0485522 , -0.12357266, ..., -0.01538112,\n",
      "        -0.08645318,  0.15357617],\n",
      "       ...,\n",
      "       [-0.16554415,  0.1123234 ,  0.08176019, ..., -0.0390388 ,\n",
      "         0.03034041,  0.13059102],\n",
      "       [ 0.05674582,  0.12206955, -0.0574114 , ...,  0.19179617,\n",
      "         0.17785501, -0.00726812],\n",
      "       [ 0.15103638,  0.14105847,  0.00103914, ...,  0.07655677,\n",
      "        -0.00906709, -0.02824692]], dtype=float32)}, 'Dense_1': {'bias': Array([0.], dtype=float32), 'kernel': Array([[-0.28016493],\n",
      "       [ 0.00162521],\n",
      "       [-0.01250711],\n",
      "       [ 0.0496256 ],\n",
      "       [ 0.18754622],\n",
      "       [-0.00834994],\n",
      "       [-0.00101195],\n",
      "       [-0.1055735 ],\n",
      "       [ 0.26273257],\n",
      "       [ 0.2233348 ],\n",
      "       [-0.13717951],\n",
      "       [-0.02771057],\n",
      "       [ 0.13871656],\n",
      "       [ 0.1798862 ],\n",
      "       [ 0.08623344],\n",
      "       [ 0.00116544],\n",
      "       [-0.0295654 ],\n",
      "       [ 0.21855974],\n",
      "       [-0.2818194 ],\n",
      "       [-0.18508543],\n",
      "       [-0.04104799],\n",
      "       [ 0.03348285],\n",
      "       [ 0.22627711],\n",
      "       [ 0.26415598],\n",
      "       [-0.1180913 ],\n",
      "       [ 0.12790146],\n",
      "       [-0.19392669],\n",
      "       [ 0.27073044],\n",
      "       [-0.08777659],\n",
      "       [ 0.12709548],\n",
      "       [-0.13714747],\n",
      "       [-0.00261351],\n",
      "       [ 0.15486625],\n",
      "       [ 0.13535835],\n",
      "       [-0.00033381],\n",
      "       [-0.01581783],\n",
      "       [ 0.13221258],\n",
      "       [ 0.20883025],\n",
      "       [-0.27444005],\n",
      "       [-0.19012153],\n",
      "       [-0.16850957],\n",
      "       [ 0.17966177],\n",
      "       [-0.04889021],\n",
      "       [ 0.13567293],\n",
      "       [ 0.08271737],\n",
      "       [-0.0487542 ],\n",
      "       [-0.02351954],\n",
      "       [ 0.05545437],\n",
      "       [-0.15495391],\n",
      "       [-0.11607981],\n",
      "       [-0.11446278],\n",
      "       [ 0.17794244],\n",
      "       [ 0.07659331],\n",
      "       [-0.08511305],\n",
      "       [-0.08084884],\n",
      "       [-0.10465908],\n",
      "       [ 0.03826824],\n",
      "       [ 0.08327684],\n",
      "       [-0.02981391],\n",
      "       [-0.01392269],\n",
      "       [-0.08856454],\n",
      "       [-0.00355701],\n",
      "       [-0.08313952],\n",
      "       [ 0.01155808]], dtype=float32)}, 'ResidualBlock_0': {'BatchNorm_0': {'bias': Array([0., 0., 0., 0.], dtype=float32), 'scale': Array([1., 1., 1., 1.], dtype=float32)}, 'BatchNorm_1': {'bias': Array([0., 0., 0., 0.], dtype=float32), 'scale': Array([1., 1., 1., 1.], dtype=float32)}, 'Conv_0': {'kernel': Array([[[[ 0.22747928,  0.05554686,  0.10208199, -0.0763793 ],\n",
      "         [ 0.2610511 ,  0.08079798, -0.05960694, -0.08229013],\n",
      "         [ 0.13500127,  0.3505997 ,  0.15699168,  0.18996137],\n",
      "         [-0.13763724,  0.19804554, -0.16069123,  0.04447618]],\n",
      "\n",
      "        [[-0.3707799 , -0.00504806,  0.01103371, -0.25164142],\n",
      "         [-0.11782183,  0.27421382, -0.07331614, -0.03348461],\n",
      "         [-0.02429948, -0.22868522, -0.00042606, -0.18761289],\n",
      "         [ 0.30703285,  0.12686422,  0.3192907 ,  0.01974931]],\n",
      "\n",
      "        [[-0.16894636, -0.1073658 , -0.0737538 ,  0.16944177],\n",
      "         [ 0.12406744,  0.04387135, -0.20167828,  0.22610442],\n",
      "         [ 0.19560805,  0.33743334,  0.02589532, -0.02327862],\n",
      "         [-0.13758758, -0.05484692, -0.12955126,  0.14564072]]],\n",
      "\n",
      "\n",
      "       [[[-0.09545435, -0.16150145, -0.14413226, -0.02501737],\n",
      "         [-0.27205342,  0.01008169, -0.02794244,  0.28611067],\n",
      "         [ 0.19097397, -0.12987337, -0.11969446, -0.02248716],\n",
      "         [-0.08609135, -0.2040785 ,  0.10908703,  0.07903732]],\n",
      "\n",
      "        [[ 0.0211049 , -0.19195648, -0.05098011, -0.05422477],\n",
      "         [-0.04984181,  0.17584696, -0.04708543,  0.11672221],\n",
      "         [-0.16140684, -0.31979907,  0.20898561, -0.16618407],\n",
      "         [ 0.24304351, -0.0253717 ,  0.02409222, -0.21249492]],\n",
      "\n",
      "        [[ 0.13632198,  0.07961302,  0.1404675 ,  0.05373683],\n",
      "         [-0.33624035, -0.13096066, -0.07121788,  0.19618814],\n",
      "         [-0.04722411, -0.2462403 , -0.11030781,  0.19784607],\n",
      "         [-0.05911671, -0.03573203, -0.0979507 , -0.07284396]]],\n",
      "\n",
      "\n",
      "       [[[-0.05116268,  0.16790983, -0.13342458, -0.21427588],\n",
      "         [ 0.17911504,  0.28960252, -0.02996453,  0.23712675],\n",
      "         [ 0.1314079 , -0.03653943, -0.04865855,  0.0274829 ],\n",
      "         [-0.34169307,  0.1330323 ,  0.19599897, -0.03330573]],\n",
      "\n",
      "        [[-0.04918488,  0.02351724,  0.12186975, -0.2900583 ],\n",
      "         [-0.16996646,  0.13054389,  0.05664274,  0.04563927],\n",
      "         [ 0.02927732, -0.23714535, -0.07129054, -0.04183791],\n",
      "         [-0.35786387,  0.10888509, -0.0271937 ,  0.12601775]],\n",
      "\n",
      "        [[-0.15101679,  0.02252678, -0.07463543, -0.1892601 ],\n",
      "         [ 0.17721504,  0.22244248,  0.28560072,  0.15082788],\n",
      "         [ 0.00387136,  0.17724946,  0.22475822,  0.1539336 ],\n",
      "         [ 0.12943877,  0.10121074,  0.2724897 , -0.19216855]]]],      dtype=float32)}, 'Conv_1': {'kernel': Array([[[[ 6.41004741e-03, -8.50414634e-02,  1.76623434e-01,\n",
      "           2.25468755e-01],\n",
      "         [ 9.34958756e-02,  8.02445859e-02,  7.39709884e-02,\n",
      "          -2.22229213e-01],\n",
      "         [-3.15287486e-02, -7.64145443e-05, -1.01376530e-02,\n",
      "          -5.40609695e-02],\n",
      "         [ 3.08608681e-01, -1.53759141e-02, -2.22227201e-01,\n",
      "          -1.38800777e-02]],\n",
      "\n",
      "        [[-2.38064617e-01,  1.00128569e-01, -2.63481259e-01,\n",
      "           1.27392560e-01],\n",
      "         [-1.71618044e-01,  1.35952890e-01,  2.00169474e-01,\n",
      "          -1.40963361e-01],\n",
      "         [-8.51869136e-02,  2.13472381e-01,  1.49991274e-01,\n",
      "           8.88220146e-02],\n",
      "         [-1.62864979e-02, -2.73625791e-01, -1.53732579e-02,\n",
      "           1.30438179e-01]],\n",
      "\n",
      "        [[-1.19172394e-01,  1.16388135e-01,  8.91230479e-02,\n",
      "          -1.41658217e-01],\n",
      "         [-4.35186066e-02, -1.38019860e-01,  1.13543883e-01,\n",
      "          -3.64979237e-01],\n",
      "         [ 2.77398806e-02,  1.34803593e-01, -1.40191793e-01,\n",
      "           3.14799666e-01],\n",
      "         [ 1.94219321e-01, -4.42487895e-02,  2.32541248e-01,\n",
      "           1.06246598e-01]]],\n",
      "\n",
      "\n",
      "       [[[ 2.23684125e-02, -3.18503201e-01,  1.12957209e-02,\n",
      "           3.01164746e-01],\n",
      "         [ 5.53199388e-02,  2.52178192e-01,  2.25557834e-01,\n",
      "          -1.74390286e-01],\n",
      "         [ 3.27725917e-01, -2.24368364e-01,  1.23116791e-01,\n",
      "           1.89703658e-01],\n",
      "         [ 3.57735753e-02, -5.03538735e-02, -5.77131771e-02,\n",
      "           4.11764309e-02]],\n",
      "\n",
      "        [[ 1.03711881e-01,  3.95701490e-02, -3.00735980e-01,\n",
      "          -6.82963431e-02],\n",
      "         [ 6.90802485e-02, -1.18622892e-01,  3.71684641e-01,\n",
      "           1.94849297e-01],\n",
      "         [-3.44346672e-01,  8.43481794e-02, -2.90249676e-01,\n",
      "          -1.05668217e-01],\n",
      "         [-5.64657748e-02, -2.39595756e-01, -6.90056980e-02,\n",
      "          -1.35547608e-01]],\n",
      "\n",
      "        [[ 5.98884858e-02,  2.45850369e-01, -3.15165758e-01,\n",
      "           1.97236985e-01],\n",
      "         [-3.06898355e-03,  4.82714251e-02, -2.14725658e-01,\n",
      "           1.59316063e-01],\n",
      "         [-4.61249761e-02, -9.90045443e-02,  4.02530283e-02,\n",
      "          -1.41352013e-01],\n",
      "         [-1.88396037e-01,  1.90964788e-01,  9.42045078e-02,\n",
      "           9.31622181e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.95088163e-01,  2.64452338e-01,  1.58213884e-01,\n",
      "           1.97445378e-01],\n",
      "         [-1.33797124e-01,  1.91184297e-01, -2.13461772e-01,\n",
      "           2.57238060e-01],\n",
      "         [ 6.35038018e-02, -1.10907011e-01, -2.82926619e-01,\n",
      "           8.35378468e-02],\n",
      "         [-1.81410298e-01, -6.85015693e-02,  7.14116320e-02,\n",
      "           2.22672686e-01]],\n",
      "\n",
      "        [[-6.33207932e-02,  2.19674513e-01, -4.88181412e-02,\n",
      "           1.86992735e-01],\n",
      "         [-2.91509986e-01,  1.83434889e-01,  8.54001045e-02,\n",
      "          -4.39389646e-02],\n",
      "         [-8.82045329e-02,  1.56521797e-02,  1.26317173e-01,\n",
      "           1.05438307e-01],\n",
      "         [ 4.36653234e-02, -1.20086290e-01, -2.75647610e-01,\n",
      "          -1.15567647e-01]],\n",
      "\n",
      "        [[-1.85123369e-01,  2.11922616e-01,  1.69366479e-01,\n",
      "           1.75818264e-01],\n",
      "         [-5.80018274e-02,  3.75932336e-01,  1.85247689e-01,\n",
      "           5.44129089e-02],\n",
      "         [-1.27318457e-01,  1.48411691e-01, -1.71210870e-01,\n",
      "          -6.73838407e-02],\n",
      "         [ 6.10118695e-02, -1.27471223e-01, -1.84733629e-01,\n",
      "           3.55648734e-02]]]], dtype=float32)}}, 'ResidualBlock_1': {'BatchNorm_0': {'bias': Array([0., 0., 0., 0.], dtype=float32), 'scale': Array([1., 1., 1., 1.], dtype=float32)}, 'BatchNorm_1': {'bias': Array([0., 0., 0., 0.], dtype=float32), 'scale': Array([1., 1., 1., 1.], dtype=float32)}, 'Conv_0': {'kernel': Array([[[[-0.12588604, -0.02804199, -0.07502705, -0.13859835],\n",
      "         [ 0.13234085, -0.16610108, -0.15942882, -0.257848  ],\n",
      "         [ 0.1101853 , -0.00232876, -0.33349645, -0.02598298],\n",
      "         [ 0.05036267,  0.32069117, -0.00981864,  0.0829051 ]],\n",
      "\n",
      "        [[-0.14530607,  0.01088923,  0.08208928, -0.2992484 ],\n",
      "         [ 0.00816321, -0.353413  , -0.08063544, -0.09003975],\n",
      "         [-0.13254997, -0.18377158, -0.0776547 , -0.02978271],\n",
      "         [ 0.27812994,  0.07102188,  0.19739997, -0.20335548]],\n",
      "\n",
      "        [[ 0.09835054,  0.05561027,  0.06784695,  0.22675778],\n",
      "         [ 0.1885436 ,  0.14555396, -0.01693977,  0.31084445],\n",
      "         [ 0.09932835, -0.30690113, -0.21583748,  0.09657437],\n",
      "         [-0.3330211 ,  0.10485357, -0.13327278,  0.11543112]]],\n",
      "\n",
      "\n",
      "       [[[ 0.2074767 , -0.30512196,  0.25733587,  0.07893162],\n",
      "         [ 0.0129907 , -0.03405289,  0.18595101,  0.02186381],\n",
      "         [-0.3508737 , -0.08050919,  0.10056984,  0.29167873],\n",
      "         [-0.2756897 , -0.08444444, -0.09372337,  0.02692957]],\n",
      "\n",
      "        [[-0.31592873,  0.07911213,  0.3433432 ,  0.06836758],\n",
      "         [ 0.16429776, -0.29431108,  0.19769482, -0.18110952],\n",
      "         [ 0.036038  ,  0.10356068, -0.03455983, -0.2717499 ],\n",
      "         [ 0.10980741,  0.20410985,  0.26036578, -0.3121741 ]],\n",
      "\n",
      "        [[ 0.228095  ,  0.08432914, -0.04252711, -0.27471638],\n",
      "         [-0.09793884, -0.03641237, -0.18380627, -0.19313619],\n",
      "         [-0.10887241, -0.17946048,  0.07546602,  0.20417874],\n",
      "         [ 0.17544973,  0.05243019, -0.1510885 , -0.1172535 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.35952586, -0.3472295 ,  0.2321062 ,  0.3165724 ],\n",
      "         [-0.036792  ,  0.04065463,  0.20968881,  0.18876967],\n",
      "         [ 0.14254317,  0.10416875, -0.27321753, -0.08087635],\n",
      "         [-0.01779114, -0.24503073, -0.01027252,  0.07877322]],\n",
      "\n",
      "        [[-0.21813487,  0.23544502, -0.01623502,  0.1400409 ],\n",
      "         [-0.1492275 , -0.28854552, -0.11945178, -0.26562765],\n",
      "         [ 0.1339192 ,  0.14484319, -0.06140393,  0.32331988],\n",
      "         [-0.27803728, -0.20279793, -0.01342035,  0.03336418]],\n",
      "\n",
      "        [[-0.02114803, -0.16180001,  0.09330731, -0.00595267],\n",
      "         [-0.10618512,  0.06141937, -0.14903368, -0.1584955 ],\n",
      "         [-0.17692384, -0.20333844,  0.26611927,  0.16379613],\n",
      "         [-0.19421381,  0.15736462, -0.04914899, -0.15712981]]]],      dtype=float32)}, 'Conv_1': {'kernel': Array([[[[-0.19923589, -0.00355278, -0.15996033, -0.25115922],\n",
      "         [-0.03448422, -0.31842762,  0.33731437,  0.05572566],\n",
      "         [ 0.02599029, -0.30061185,  0.13763188,  0.01835764],\n",
      "         [-0.29290745,  0.1641283 , -0.15964597,  0.08514781]],\n",
      "\n",
      "        [[ 0.04992824, -0.12232821, -0.19411151,  0.24849343],\n",
      "         [ 0.04171471,  0.16400053,  0.18226776,  0.08273386],\n",
      "         [ 0.13476059,  0.05497541, -0.04087542, -0.08413581],\n",
      "         [ 0.2450088 ,  0.01162121, -0.18430573,  0.05613339]],\n",
      "\n",
      "        [[-0.36828667, -0.24102177, -0.24566476, -0.14060926],\n",
      "         [-0.14217414,  0.15065643,  0.05972841, -0.17358501],\n",
      "         [ 0.06132904, -0.06726947, -0.05077006,  0.10284448],\n",
      "         [ 0.14655659,  0.11097643,  0.10146956, -0.03868966]]],\n",
      "\n",
      "\n",
      "       [[[-0.21228828,  0.16499375, -0.1516318 , -0.11622151],\n",
      "         [-0.23417224,  0.00995338,  0.0141138 ,  0.1103831 ],\n",
      "         [-0.11425167,  0.16564074, -0.02630461, -0.10186798],\n",
      "         [-0.26926947, -0.2103564 , -0.15826818,  0.04091088]],\n",
      "\n",
      "        [[ 0.00807553, -0.18716906, -0.17992131,  0.19072187],\n",
      "         [ 0.32329163, -0.08420948,  0.08113742, -0.16734844],\n",
      "         [-0.14096078,  0.05432292, -0.04869234,  0.21745658],\n",
      "         [-0.02152818,  0.22673035,  0.26006982,  0.08313126]],\n",
      "\n",
      "        [[ 0.21363129,  0.03883744, -0.25407118,  0.09050006],\n",
      "         [-0.03846627,  0.1717165 ,  0.11471608, -0.06715298],\n",
      "         [-0.11070871, -0.10829891,  0.1951725 , -0.07127558],\n",
      "         [ 0.32761598,  0.34619942,  0.16570522, -0.20260946]]],\n",
      "\n",
      "\n",
      "       [[[-0.19114865, -0.019117  , -0.2294924 , -0.11588903],\n",
      "         [-0.23344153,  0.12354666, -0.00875858, -0.06098011],\n",
      "         [ 0.12769908,  0.15934066,  0.051624  ,  0.03964836],\n",
      "         [-0.251226  , -0.10617058, -0.08024252, -0.29337278]],\n",
      "\n",
      "        [[-0.09773161,  0.30117235, -0.1674081 , -0.01976811],\n",
      "         [ 0.01654476,  0.1656535 , -0.15706672,  0.10031696],\n",
      "         [-0.01721298, -0.02915821, -0.01206506, -0.00670172],\n",
      "         [ 0.22134653, -0.10155111, -0.1407059 ,  0.00864947]],\n",
      "\n",
      "        [[-0.2735646 , -0.04273175,  0.07066749,  0.3401186 ],\n",
      "         [-0.05841335,  0.19066894, -0.16750781,  0.00740453],\n",
      "         [-0.12531301,  0.07505242,  0.1968601 , -0.06469911],\n",
      "         [ 0.00312887,  0.03747489,  0.11885057,  0.14566368]]]],      dtype=float32)}}}}\n",
      "Epoch 2: {'loss': Array(2.7885928, dtype=float32), 'policy_accuracy': Array(0.17773438, dtype=float32), 'policy_loss': Array(2.217349, dtype=float32), 'value_accuracy': Array(0.15722656, dtype=float32), 'value_loss': Array(0.55984414, dtype=float32)}\n"
     ]
    },
    {
     "ename": "ApplyScopeInvalidVariablesTypeError",
     "evalue": "The first argument passed to an apply function should be a dictionary of collections. Each collection should be a dictionary with string keys. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ApplyScopeInvalidVariablesTypeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApplyScopeInvalidVariablesTypeError\u001b[0m       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collection_state, train_state, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_episodes_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/turbozero/core/training/train_2p.py:189\u001b[0m, in \u001b[0;36mTwoPlayerTrainer.train_loop\u001b[0;34m(self, key, batch_size, train_state, warmup_steps, collection_steps_per_epoch, train_steps_per_epoch, test_episodes_per_epoch, num_epochs, cur_epoch, best_params, collection_state)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_model_params_fn(train_state)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_episodes_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_episodes_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_state\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/turbozero/core/training/train.py:319\u001b[0m, in \u001b[0;36mTrainer.train_loop\u001b[0;34m(self, key, batch_size, train_state, warmup_steps, collection_steps_per_epoch, train_steps_per_epoch, test_episodes_per_epoch, num_epochs, cur_epoch, best_params, collection_state)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_metrics(metrics, cur_epoch, step\u001b[38;5;241m=\u001b[39mcollection_steps)\n\u001b[1;32m    318\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_model_params_fn(train_state)\n\u001b[0;32m--> 319\u001b[0m collection_state, metrics, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_metrics(metrics, cur_epoch, step\u001b[38;5;241m=\u001b[39mcollection_steps)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_checkpoint(train_state, cur_epoch, best_params)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Repos/turbozero/core/training/train_2p.py:134\u001b[0m, in \u001b[0;36mTwoPlayerTrainer.test\u001b[0;34m(self, collection_state, params, num_episodes, best_params)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mwhile_loop(\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[38;5;241m~\u001b[39ms\u001b[38;5;241m.\u001b[39mcompleted,\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m s: step_step(s),\n\u001b[1;32m    129\u001b[0m         state\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# make one step, reset half of environments\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# so that new params go first half the time     \u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m test_state \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_best\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m reset \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros((num_episodes))\n\u001b[1;32m    136\u001b[0m reset \u001b[38;5;241m=\u001b[39m reset\u001b[38;5;241m.\u001b[39mat[:num_episodes \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Repos/turbozero/core/training/train_2p.py:31\u001b[0m, in \u001b[0;36mTwoPlayerTrainer.test_step\u001b[0;34m(self, state, params)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     27\u001b[0m     state: TwoPlayerTestState,\n\u001b[1;32m     28\u001b[0m     params: chex\u001b[38;5;241m.\u001b[39mArrayTree,\n\u001b[1;32m     29\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[chex\u001b[38;5;241m.\u001b[39mArrayTree, chex\u001b[38;5;241m.\u001b[39mArrayTree, chex\u001b[38;5;241m.\u001b[39mArrayTree, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m     30\u001b[0m     new_key, step_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(state\u001b[38;5;241m.\u001b[39mkey)\n\u001b[0;32m---> 31\u001b[0m     env_state, output, metadata, terminated, rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_env_and_evaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcur_player_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     cur_player_state \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39meval_state\n\u001b[1;32m     40\u001b[0m     other_player_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mstep(state\u001b[38;5;241m.\u001b[39mother_player_state, output\u001b[38;5;241m.\u001b[39maction)\n",
      "File \u001b[0;32m~/Repos/turbozero/core/training/train.py:113\u001b[0m, in \u001b[0;36mTrainer._step_env_and_evaluator\u001b[0;34m(self, key, env_state, eval_state, metadata, params, is_test)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step_env_and_evaluator\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    105\u001b[0m     key: jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey,\n\u001b[1;32m    106\u001b[0m     env_state: chex\u001b[38;5;241m.\u001b[39mArrayTree,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     is_test: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    111\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[chex\u001b[38;5;241m.\u001b[39mArrayTree, EvalOutput, StepMetadata, \u001b[38;5;28mbool\u001b[39m, chex\u001b[38;5;241m.\u001b[39mArray]:\n\u001b[1;32m    112\u001b[0m     evaluate_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_test \u001b[38;5;28;01mif\u001b[39;00m is_test \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_train\n\u001b[0;32m--> 113\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     eval_state \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39meval_state\n\u001b[1;32m    115\u001b[0m     env_state, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_step_fn(env_state, output\u001b[38;5;241m.\u001b[39maction)\n",
      "File \u001b[0;32m~/Repos/turbozero/core/evaluators/mcts/mcts.py:38\u001b[0m, in \u001b[0;36mMCTS.evaluate\u001b[0;34m(self, eval_state, env_state, root_metadata, params, num_iterations, env_step_fn, eval_fn, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     29\u001b[0m     eval_state: MCTSTree, \n\u001b[1;32m     30\u001b[0m     env_state: chex\u001b[38;5;241m.\u001b[39mArrayTree,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MCTSOutput:\n\u001b[0;32m---> 38\u001b[0m     eval_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     iterate \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate, \n\u001b[1;32m     40\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     41\u001b[0m         env_step_fn\u001b[38;5;241m=\u001b[39menv_step_fn,\n\u001b[1;32m     42\u001b[0m         eval_fn\u001b[38;5;241m=\u001b[39meval_fn\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     eval_state \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mfori_loop(\u001b[38;5;241m0\u001b[39m, num_iterations, \u001b[38;5;28;01mlambda\u001b[39;00m _, t: iterate(t), eval_state)\n",
      "File \u001b[0;32m~/Repos/turbozero/core/evaluators/alphazero.py:26\u001b[0m, in \u001b[0;36mAlphaZero.update_root\u001b[0;34m(self, tree, root_embedding, root_metadata, params, eval_fn)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_root\u001b[39m(\u001b[38;5;28mself\u001b[39m, tree: MCTSTree, root_embedding: chex\u001b[38;5;241m.\u001b[39mArrayTree, root_metadata: StepMetadata, params: chex\u001b[38;5;241m.\u001b[39mArrayTree, eval_fn: EvalFn) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MCTSTree:\n\u001b[0;32m---> 26\u001b[0m     root_policy_logits, root_value \u001b[38;5;241m=\u001b[39m \u001b[43meval_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     root_policy \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(root_policy_logits)\n\u001b[1;32m     29\u001b[0m     dir_key, new_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(tree\u001b[38;5;241m.\u001b[39mkey)\n",
      "Cell \u001b[0;32mIn[2], line 85\u001b[0m, in \u001b[0;36meval_fn\u001b[0;34m(state, params)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_fn\u001b[39m(state, params):\n\u001b[0;32m---> 85\u001b[0m     policy_logits, value \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(policy_logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), \\\n\u001b[1;32m     87\u001b[0m             value\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/turbozero-mMa0U6zx-py3.10/lib/python3.10/site-packages/flax/core/scope.py:1037\u001b[0m, in \u001b[0;36mbind\u001b[0;34m(variables, rngs, mutable, flags)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binds variables and rngs to a new ``Scope``.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03mbind provides a ``Scope`` instance without transforming a function with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m  A new scope with the variables and rngs bound to it.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_variables(variables):\n\u001b[0;32m-> 1037\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mApplyScopeInvalidVariablesTypeError()\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rngs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_rngs(rngs):\n\u001b[1;32m   1039\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidRngError(\n\u001b[1;32m   1040\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrngs should be a dictionary mapping strings to `jax.PRNGKey`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1041\u001b[0m   )\n",
      "\u001b[0;31mApplyScopeInvalidVariablesTypeError\u001b[0m: The first argument passed to an apply function should be a dictionary of collections. Each collection should be a dictionary with string keys. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ApplyScopeInvalidVariablesTypeError)"
     ]
    }
   ],
   "source": [
    "collection_state, train_state, best_params = trainer.train_loop(\n",
    "    key=jax.random.PRNGKey(0),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_state=train_state, \n",
    "    warmup_steps=64, \n",
    "    collection_steps_per_epoch=128,\n",
    "    train_steps_per_epoch=16,\n",
    "    test_episodes_per_epoch=10,\n",
    "    num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User defines:\n",
    "* Environment dynamics\n",
    "    * env_step_fn\n",
    "    * env_init_fn\n",
    "* Model\n",
    "    * evaluation_fn\n",
    "* flax.train_state.TrainState\n",
    "    * train_step_fn\n",
    "    * extract_model_params_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph.svg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.evaluators.mcts.data import tree_to_graph\n",
    "graph = tree_to_graph(collection_state.eval_state, batch_id=0)\n",
    "graph.render('graph', format='svg', view=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turbozero-mMa0U6zx-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
